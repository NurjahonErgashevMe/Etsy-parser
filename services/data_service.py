"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏
–°—Ç—Ä—É–∫—Ç—É—Ä–∞: output/parsing/ (–Ω–æ–≤–∏–Ω–∫–∏), output/tops/ (—Ç–æ–ø —Ç–æ–≤–∞—Ä—ã)
"""
import os
import pandas as pd
import glob
import json
import shutil
import logging
from datetime import datetime
from typing import List, Optional, Dict
from models.product import Product, ShopComparison

class DataService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, config):
        self.config = config
        self.output_dir = config.output_dir
        
        self.parsing_dir = os.path.join(self.output_dir, "parsing")
        self.tops_dir = os.path.join(self.output_dir, "tops")
        
        self.current_parsing_folder = None
        self.current_parsing_dir = None
        
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.parsing_dir, exist_ok=True)
        os.makedirs(self.tops_dir, exist_ok=True)
        
        logging.info(f"üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞: parsing={self.parsing_dir}, tops={self.tops_dir}")
    
    def start_parsing_session(self) -> str:
        """–°–æ–∑–¥–∞—ë—Ç –ø–∞–ø–∫—É –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–µ–∞–Ω—Å–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        self.current_parsing_folder = datetime.now().strftime("%d.%m.%Y_%H.%M")
        self.current_parsing_dir = os.path.join(self.parsing_dir, self.current_parsing_folder)
        os.makedirs(self.current_parsing_dir, exist_ok=True)
        
        print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: parsing/{self.current_parsing_folder}")
        return self.current_parsing_dir
    
    def save_products_to_excel(self, products: List[Product], shop_name: str) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–¥—É–∫—Ç—ã –≤ Excel —Ñ–∞–π–ª"""
        if not products:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return None
        
        if not self.current_parsing_dir:
            self.start_parsing_session()
        
        filename = os.path.join(self.current_parsing_dir, f"{shop_name}.xlsx")
        data = [product.to_dict() for product in products]
        df = pd.DataFrame(data)
        df.to_excel(filename, index=False)
        
        print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")
        return filename
    
    def load_products_from_excel(self, filename: str) -> List[Product]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–¥—É–∫—Ç—ã –∏–∑ Excel —Ñ–∞–π–ª–∞"""
        try:
            df = pd.read_excel(filename)
            products = []
            
            for _, row in df.iterrows():
                product = Product.from_dict(row.to_dict())
                products.append(product)
            
            return products
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {filename}: {e}")
            return []
    
    def get_latest_file_for_shop(self, shop_name: str) -> Optional[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Ñ–∞–π–ª—É –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞"""
        pattern = f"{self.parsing_dir}/*/{shop_name}.xlsx"
        files = glob.glob(pattern)
        
        if not files:
            old_pattern = f"{self.output_dir}/{shop_name}_*.xlsx"
            files = glob.glob(old_pattern)
            
            legacy_pattern = f"{self.output_dir}/*/{shop_name}.xlsx"
            legacy_files = glob.glob(legacy_pattern)
            legacy_files = [f for f in legacy_files if not any(x in f for x in ["/parsing/", "/tops/", "\\parsing\\", "\\tops\\"])]
            files.extend(legacy_files)
        
        if not files:
            return None
        
        files.sort(key=os.path.getctime, reverse=True)
        return files[0]
    
    def get_previous_file_for_shop(self, shop_name: str) -> Optional[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Ñ–∞–π–ª—É –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞"""
        pattern = f"{self.parsing_dir}/*/{shop_name}.xlsx"
        files = glob.glob(pattern)
        
        old_pattern = f"{self.output_dir}/{shop_name}_*.xlsx"
        files.extend(glob.glob(old_pattern))
        
        legacy_pattern = f"{self.output_dir}/*/{shop_name}.xlsx"
        legacy_files = glob.glob(legacy_pattern)
        legacy_files = [f for f in legacy_files if not any(x in f for x in ["/parsing/", "/tops/", "\\parsing\\", "\\tops\\"])]
        files.extend(legacy_files)
        
        if len(files) < 2:
            return None
        
        files.sort(key=os.path.getctime, reverse=True)
        return files[1]
    
    def get_all_files_for_shop(self, shop_name: str) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –¥–ª—è –º–∞–≥–∞–∑–∏–Ω–∞"""
        pattern = f"{self.parsing_dir}/*/{shop_name}.xlsx"
        files = glob.glob(pattern)
        
        old_pattern = f"{self.output_dir}/{shop_name}_*.xlsx"
        files.extend(glob.glob(old_pattern))
        
        legacy_pattern = f"{self.output_dir}/*/{shop_name}.xlsx"
        legacy_files = glob.glob(legacy_pattern)
        legacy_files = [f for f in legacy_files if not any(x in f for x in ["/parsing/", "/tops/", "\\parsing\\", "\\tops\\"])]
        files.extend(legacy_files)
        
        files.sort(key=os.path.getctime, reverse=True)
        return files
    
    def compare_shop_data(self, current_products: List[Product], shop_name: str) -> Optional[ShopComparison]:
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏"""
        previous_file = self.get_previous_file_for_shop(shop_name)
        
        if not previous_file:
            print(f"–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞ {shop_name}")
            return None
        
        previous_products = self.load_products_from_excel(previous_file)
        
        if not previous_products:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {shop_name}")
            return None
        
        current_ids = {p.listing_id for p in current_products}
        previous_ids = {p.listing_id for p in previous_products}
        
        new_ids = current_ids - previous_ids
        removed_ids = previous_ids - current_ids
        
        new_products = [p for p in current_products if p.listing_id in new_ids]
        removed_products = [p for p in previous_products if p.listing_id in removed_ids]
        
        comparison = ShopComparison(
            shop_name=shop_name,
            new_products=new_products,
            removed_products=removed_products,
            total_current=len(current_products),
            total_previous=len(previous_products),
            comparison_date=datetime.now()
        )
        
        return comparison
    
    def print_comparison_results(self, comparison: ShopComparison):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print(f"\n=== –°–†–ê–í–ù–ï–ù–ò–ï –î–õ–Ø {comparison.shop_name} ===")
        print(f"–¢–µ–∫—É—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤: {comparison.total_current}")
        print(f"–ü—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤: {comparison.total_previous}")
        print(f"–ù–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(comparison.new_products)}")
        print(f"–£–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(comparison.removed_products)}")
        
        if comparison.new_products:
            print("\n–ù–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã:")
            for product in comparison.new_products:
                print(f"  - {product.title} (ID: {product.listing_id})")
        
        if comparison.removed_products:
            print("\n–£–¥–∞–ª–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã:")
            for product in comparison.removed_products:
                print(f"  - {product.title} (ID: {product.listing_id})")
        
        if not comparison.has_changes:
            print("–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
    
    def save_results_to_json(self, all_shop_products: Dict[str, List[Product]]) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ results.json"""
        if not self.current_parsing_dir:
            self.start_parsing_session()
        
        results_file = os.path.join(self.current_parsing_dir, "results.json")
        
        shops_data = {}
        for shop_name, products in all_shop_products.items():
            shops_data[shop_name] = {product.listing_id: product.url for product in products}
        
        results = {"shops": shops_data}
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
        return results_file
    
    def load_results_from_json(self, results_file: str) -> Optional[Dict[str, Dict[str, str]]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ results.json"""
        try:
            with open(results_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get("shops", {})
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {results_file}: {e}")
            return None
    
    def get_previous_results_file(self) -> Optional[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª results.json"""
        current_folder_name = self.current_parsing_folder if self.current_parsing_folder else datetime.now().strftime("%d.%m.%Y_%H.%M")
        date_folders = []
        
        if os.path.exists(self.parsing_dir):
            for item in os.listdir(self.parsing_dir):
                item_path = os.path.join(self.parsing_dir, item)
                if os.path.isdir(item_path) and item != current_folder_name:
                    results_file = os.path.join(item_path, "results.json")
                    if os.path.exists(results_file):
                        try:
                            folder_datetime = datetime.strptime(item, "%d.%m.%Y_%H.%M") if "_" in item else datetime.strptime(item, "%d.%m.%Y")
                            date_folders.append((folder_datetime, results_file))
                        except ValueError:
                            continue
        
        if os.path.exists(self.output_dir):
            for item in os.listdir(self.output_dir):
                if item in ["parsing", "tops"]:
                    continue
                    
                item_path = os.path.join(self.output_dir, item)
                if os.path.isdir(item_path) and item != current_folder_name:
                    results_file = os.path.join(item_path, "results.json")
                    if os.path.exists(results_file):
                        try:
                            folder_datetime = datetime.strptime(item, "%d.%m.%Y_%H.%M") if "_" in item else datetime.strptime(item, "%d.%m.%Y")
                            date_folders.append((folder_datetime, results_file))
                        except ValueError:
                            continue
        
        if not date_folders:
            return None
        
        date_folders.sort(key=lambda x: x[0], reverse=True)
        return date_folders[0][1]
    
    def compare_all_shops_results(self, current_results: Dict[str, Dict[str, str]]) -> Dict[str, str]:
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã"""
        previous_results_file = self.get_previous_results_file()
        
        if not previous_results_file:
            print("–ù–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è - –≤—Å–µ —Ç–æ–≤–∞—Ä—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –Ω–æ–≤—ã–º–∏")
            new_products = {}
            for shop_name, shop_products in current_results.items():
                new_products.update(shop_products)
            return new_products
        
        previous_results = self.load_results_from_json(previous_results_file)
        
        if not previous_results:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –≤—Å–µ —Ç–æ–≤–∞—Ä—ã —Å—á–∏—Ç–∞—é—Ç—Å—è –Ω–æ–≤—ã–º–∏")
            new_products = {}
            for shop_name, shop_products in current_results.items():
                new_products.update(shop_products)
            return new_products
        
        new_products = {}
        
        # print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–∞–≥–∞–∑–∏–Ω—ã:")
        # print(f"  –¢–µ–∫—É—â–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã: {list(current_results.keys())}")
        # print(f"  –ü—Ä–µ–¥—ã–¥—É—â–∏–µ –º–∞–≥–∞–∑–∏–Ω—ã: {list(previous_results.keys())}")
        
        for shop_name in current_results:
            if shop_name in previous_results:
                current_listings = set(current_results[shop_name].keys())
                previous_listings = set(previous_results[shop_name].keys())
                
                print(f"  –ú–∞–≥–∞–∑–∏–Ω {shop_name}:")
                print(f"    –¢–µ–∫—É—â–∏–µ —Ç–æ–≤–∞—Ä—ã: {len(current_listings)}")
                print(f"    –ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Ç–æ–≤–∞—Ä—ã: {len(previous_listings)}")
                
                new_listing_ids = current_listings - previous_listings
                
                if new_listing_ids:
                    print(f"    –ù–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã: {list(new_listing_ids)}")
                    for listing_id in new_listing_ids:
                        new_products[listing_id] = current_results[shop_name][listing_id]
                    print(f"–ú–∞–≥–∞–∑–∏–Ω {shop_name}: –Ω–∞–π–¥–µ–Ω–æ {len(new_listing_ids)} –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
                else:
                    print(f"    –ù–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            else:
                print(f"–ú–∞–≥–∞–∑–∏–Ω {shop_name}: –Ω–æ–≤—ã–π –º–∞–≥–∞–∑–∏–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ")
        
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(new_products)}")
        # if new_products:
        #     print("–°–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤:")
        #     for listing_id, url in new_products.items():
        #         print(f"  - {listing_id}: {url}")

        
        return new_products
    
    def save_results_with_new_products(self, all_shop_products: Dict[str, List[Product]], new_products: Dict[str, str], new_products_full_data: Dict[str, Product] = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –Ω–æ–≤—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏"""
        if not self.current_parsing_dir:
            self.start_parsing_session()
        
        results_file = os.path.join(self.current_parsing_dir, "results.json")
        
        shops_data = {}
        for shop_name, products in all_shop_products.items():
            shops_data[shop_name] = {product.listing_id: product.url for product in products}
        
        results = {
            "shops": shops_data,
            "new_products": new_products
        }
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –Ω–æ–≤—ã–º–∏ —Ç–æ–≤–∞—Ä–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
        self.save_new_products_to_sheets(new_products, results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ new_perspective_listings.json
        if new_products:
            self.save_new_perspective_listings(new_products, new_products_full_data)
        
        return results_file
    
    def save_new_perspective_listings(self, new_products: Dict[str, str], new_products_full_data: Dict[str, Product] = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ new_perspective_listings.json —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ EverBee"""
        from utils.everbee_client import EverBeeClient
        
        new_listings_file = os.path.join(self.tops_dir, "new_perspective_listings.json")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        existing_data = {"listings": {}}
        if os.path.exists(new_listings_file):
            try:
                with open(new_listings_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {new_listings_file}: {e}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ EverBee –ø–∞–∫–µ—Ç–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
        everbee_client = EverBeeClient()
        current_session = self.current_parsing_folder or datetime.now().strftime("%d.%m.%Y_%H.%M")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        listing_ids = list(new_products.keys())
        everbee_data_batch = {}
        
        try:
            if listing_ids:
                batch_data = everbee_client.get_listings_batch(listing_ids)
                if batch_data and 'results' in batch_data:
                    for listing_info in batch_data['results']:
                        listing_id = str(listing_info.get('listing_id', ''))
                        everbee_data_batch[listing_id] = everbee_client.extract_listing_data(listing_info)
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞–∫–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö EverBee: {e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        for listing_id, url in new_products.items():
            if listing_id not in existing_data["listings"]:
                existing_data["listings"][listing_id] = {}
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ —Ç–æ–ª—å–∫–æ URL
            everbee_data = everbee_data_batch.get(listing_id, {"url": url})
            existing_data["listings"][listing_id][current_session] = everbee_data
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        with open(new_listings_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
        
        logging.info(f"–ù–æ–≤—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–∏ —Å EverBee –¥–∞–Ω–Ω—ã–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {new_listings_file}: {len(new_products)} —Ç–æ–≤–∞—Ä–æ–≤")
    
    def save_new_products_to_sheets(self, new_products: Dict[str, str], results: Dict = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ Google Sheets"""
        if not new_products:
            return
        
        if hasattr(self.config, 'google_sheets_enabled') and self.config.google_sheets_enabled:
            try:
                from services.google_sheets_service import GoogleSheetsService
                sheets_service = GoogleSheetsService(self.config)
                
                if sheets_service.enabled:
                    sheets_service.add_new_products_to_sheets(
                        self.config.google_sheets_spreadsheet_id,
                        new_products,
                        "Etsy Products",
                        results
                    )
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Google Sheets: {e}")
    
    def cleanup_output_folder(self) -> bool:
        """–û—á–∏—â–∞–µ—Ç –ø–∞–ø–∫—É parsing/, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â—É—é. –ü–∞–ø–∫–∞ tops/ –Ω–µ —Ç—Ä–æ–≥–∞–µ—Ç—Å—è."""
        if not self.current_parsing_folder:
            return True
        
        try:
            folders_to_delete = []
            
            if os.path.exists(self.parsing_dir):
                for item in os.listdir(self.parsing_dir):
                    item_path = os.path.join(self.parsing_dir, item)
                    if os.path.isdir(item_path) and item != self.current_parsing_folder:
                        folders_to_delete.append(item_path)
            
            if os.path.exists(self.output_dir):
                for item in os.listdir(self.output_dir):
                    if item in ["parsing", "tops"]:
                        continue
                    
                    item_path = os.path.join(self.output_dir, item)
                    if os.path.isdir(item_path):
                        folders_to_delete.append(item_path)
            
            if not folders_to_delete:
                return True
            
            deleted_count = 0
            for folder_path in folders_to_delete:
                try:
                    shutil.rmtree(folder_path, ignore_errors=True)
                    if not os.path.exists(folder_path):
                        deleted_count += 1
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {folder_path}: {e}")
            
            logging.info(f"–û—á–∏—Å—Ç–∫–∞ parsing/: —É–¥–∞–ª–µ–Ω–æ {deleted_count}/{len(folders_to_delete)} –ø–∞–ø–æ–∫")
            return True
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")
            return False
    
    def load_shop_urls(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ URL –º–∞–≥–∞–∑–∏–Ω–æ–≤ –∏–∑ Google Sheets"""
        if hasattr(self.config, 'google_sheets_enabled') and self.config.google_sheets_enabled:
            try:
                from services.google_sheets_service import GoogleSheetsService
                sheets_service = GoogleSheetsService(self.config)
                
                if sheets_service.enabled:
                    urls = sheets_service.load_shop_urls_from_sheets(
                        self.config.google_sheets_spreadsheet_id,
                        "Etsy Shops"
                    )
                    if urls:
                        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(urls)} URL –∏–∑ Google Sheets")
                        return urls
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Google Sheets: {e}")
        
        return []
