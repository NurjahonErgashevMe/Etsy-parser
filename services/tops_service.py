"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–æ–ø —Ç–æ–≤–∞—Ä–∞–º–∏
"""
import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Callable
from utils.everbee_client import EverBeeClient


class TopsService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤"""
    
    def __init__(self, tops_dir: str = "output/tops"):
        self.tops_dir = tops_dir
        self.everbee_client = EverBeeClient()
        self.listings_file = os.path.join(self.tops_dir, "new_perspective_listings.json")
        self.top_listings_file = os.path.join(self.tops_dir, "top-listings.json")
        self.notifier: Optional[Callable[[Dict], None]] = None
        os.makedirs(self.tops_dir, exist_ok=True)
    
    def _load_existing_listings(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤"""
        if os.path.exists(self.listings_file):
            try:
                with open(self.listings_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        return {"listings": {}}
    
    def _save_listings(self, data: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤"""
        try:
            with open(self.listings_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logging.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.listings_file}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")

    # ===== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —Ç–æ–ø–æ–≤/–∞—Ä—Ö–∏–≤–∞ =====
    def _load_top_listings(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏"""
        if os.path.exists(self.top_listings_file):
            try:
                with open(self.top_listings_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–æ–≤: {e}")
        return {"listings": {}}

    def _save_top_listings(self, data: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏"""
        try:
            with open(self.top_listings_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logging.info(f"–¢–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.top_listings_file}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–æ–≤: {e}")



    def set_notifier(self, notifier: Callable[[Dict], None]):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–ª–±—ç–∫ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Ç–æ–ø–∞—Ö"""
        self.notifier = notifier

    def _check_listings_age(self, data: Dict, current_date: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ –∏ –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–ø—ã"""
        potential_tops = []
        try:
            current_dt = datetime.strptime(current_date, "%d.%m.%Y_%H.%M")
            top_json = self._load_top_listings()
            
            for listing_id, snapshots in data.get("listings", {}).items():
                if not snapshots:
                    continue
                
                timestamps = sorted(snapshots.keys())
                first_ts = timestamps[0]
                last_ts = timestamps[-1]
                
                try:
                    first_dt = datetime.strptime(first_ts, "%d.%m.%Y_%H.%M")
                    days_diff = (current_dt.date() - first_dt.date()).days
                    
                    if days_diff > 0:
                        first_data = snapshots.get(first_ts, {})
                        last_data = snapshots.get(last_ts, {})
                        url = last_data.get("url", "")
                        
                        views_start = first_data.get("views", 0)
                        views_end = last_data.get("views", 0)
                        likes_start = first_data.get("num_favorers", 0)
                        likes_end = last_data.get("num_favorers", 0)
                        
                        views_growth = views_end - views_start
                        likes_growth = likes_end - likes_start
                        
                        logging.info(
                            f"–õ–∏—Å—Ç–∏–Ω–≥ {listing_id} –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è {days_diff} –¥–Ω. "
                            f"(—Å {first_ts} –¥–æ {current_date}) {url}"
                        )
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –¥–ª—è —Ç–æ–ø–∞: +20 –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –∏ +5 –ª–∞–π–∫–æ–≤
                        if views_growth >= 20 and likes_growth >= 5:
                            logging.info(
                                f"üî• –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ô –¢–û–ü: {listing_id} | "
                                f"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã: +{views_growth} | –õ–∞–π–∫–∏: +{likes_growth} | {url}"
                            )
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ç–æ–ø—ã
                            summary = {
                                "listing_id": listing_id,
                                "url": url,
                                "discovered_at": first_ts,
                                "became_hit_at": last_ts,
                                "views_start": views_start,
                                "views_hit": views_end,
                                "likes_start": likes_start,
                                "likes_hit": likes_end,
                                "reviews": last_data.get("est_reviews", 0),
                                "days_observed": days_diff
                            }
                            
                            top_json.setdefault("listings", {})
                            top_json["listings"][listing_id] = summary
                            potential_tops.append(listing_id)
                            
                            print(
                                f"üî• –¢–æ–ø-—Ö–∏—Ç: {listing_id} | "
                                f"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã: +{views_growth} | –õ–∞–π–∫–∏: +{likes_growth} | {url}"
                            )
                            
                except Exception:
                    continue
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ø—ã –∏ —É–¥–∞–ª—è–µ–º –∏—Ö –∏–∑ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö
            if potential_tops:
                self._save_top_listings(top_json)
                # –£–¥–∞–ª—è–µ–º —Ç–æ–ø—ã –∏–∑ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤
                for lid in potential_tops:
                    data["listings"].pop(lid, None)
                self._save_listings(data)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–ø—ã –≤ Google Sheets
                self._send_tops_to_sheets(top_json["listings"])
                    
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤: {e}")
        
        return potential_tops
    
    def _send_tops_to_sheets(self, top_listings: Dict):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏ –≤ Google Sheets"""
        try:
            from config.settings import config
            from services.google_sheets_service import GoogleSheetsService
            
            spreadsheet_id = config.google_sheets_spreadsheet_id
            
            if not spreadsheet_id:
                logging.warning("–ù–µ —É–∫–∞–∑–∞–Ω google_sheets_spreadsheet_id –≤ –∫–æ–Ω—Ñ–∏–≥–µ")
                return
            
            sheets_service = GoogleSheetsService(config)
            sheets_service.add_top_listings_to_sheets(spreadsheet_id, top_listings)
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–æ–ø–æ–≤ –≤ Google Sheets: {e}")
    
    def format_top_hit_message(self, summary: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç–æ–ø-—Ö–∏—Ç–µ"""
        return f"""üî• <b>–ù–ê–ô–î–ï–ù –¢–û–ü-–•–ò–¢!</b>

üîó <b>–°—Å—ã–ª–∫–∞:</b> <a href='{summary['url']}'>–û—Ç–∫—Ä—ã—Ç—å –Ω–∞ Etsy</a>

üìÖ <b>–ö–æ–≥–¥–∞ –ø–æ—è–≤–∏–ª—Å—è:</b> {summary['discovered_at']}
üéÜ <b>–ö–æ–≥–¥–∞ —Å—Ç–∞–ª —Ö–∏—Ç–æ–º:</b> {summary['became_hit_at']}

üëÄ <b>–ü—Ä–æ—Å–º–æ—Ç—Ä—ã:</b> {summary['views_start']} ‚Üí {summary['views_hit']} (+{summary['views_hit'] - summary['views_start']})
‚ù§Ô∏è <b>–õ–∞–π–∫–∏:</b> {summary['likes_start']} ‚Üí {summary['likes_hit']} (+{summary['likes_hit'] - summary['likes_start']})
‚≠ê <b>–û—Ç–∑—ã–≤—ã:</b> {summary['reviews']}

üìà <b>–î–Ω–µ–π –Ω–∞–±–ª—é–¥–µ–Ω–∏—è:</b> {summary['days_observed']}"""
        
        return potential_tops

    def cleanup_perspective_from_tops(self) -> int:
        """–£–¥–∞–ª—è–µ—Ç –∏–∑ new_perspective_listings.json –ª–∏—Å—Ç–∏–Ω–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ —Ç–æ–ø–∞—Ö.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö.
        """
        data = self._load_existing_listings()
        tops = self._load_top_listings()
        perspective = data.get("listings", {})
        top_ids = set(tops.get("listings", {}).keys())
        if not perspective or not top_ids:
            return 0
        removed = 0
        for lid in list(perspective.keys()):
            if lid in top_ids:
                perspective.pop(lid, None)
                removed += 1
        if removed:
            data["listings"] = perspective
            self._save_listings(data)
            logging.info(f"–û—á–∏—Å—Ç–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö: —É–¥–∞–ª–µ–Ω–æ {removed} —É–∂–µ-—Ç–æ–ø –ª–∏—Å—Ç–∏–Ω–≥–æ–≤")
            print(f"üßπ –û—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª–µ–Ω–æ {removed} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤, —É–∂–µ –ø–æ–ø–∞–≤—à–∏—Ö –≤ —Ç–æ–ø")
        return removed
    
    def analyze_new_listings(self, new_products: Dict[str, str], checked_date: str) -> Dict[str, Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ EverBee API"""
        if not new_products:
            print("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return {}
        
        print(f"üìä –ê–Ω–∞–ª–∏–∑ {len(new_products)} –Ω–æ–≤—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ EverBee...")
        logging.info(f"–ê–Ω–∞–ª–∏–∑ {len(new_products)} –Ω–æ–≤—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ EverBee...")
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        top_existing = set(self._load_top_listings().get("listings", {}).keys())
        listing_ids = [lid for lid in new_products.keys() if lid not in top_existing]
        
        response = self.everbee_client.get_listings_batch(listing_ids)
        
        if not response or "results" not in response:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
            logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
            return {}
        
        results = {}
        for listing in response.get("results", []):
            listing_id = str(listing.get("listing_id"))
            if listing_id:
                extracted_data = self.everbee_client.extract_listing_data(listing)
                results[listing_id] = extracted_data
        
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(results)} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ –æ—Ç EverBee")
        logging.info(f"–ü–æ–ª—É—á–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(results)} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤")
        return results
    
    def update_listings_data(self, new_listings_data: Dict[str, Dict], checked_date: str):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —Å –Ω–æ–≤–æ–π –¥–∞—Ç–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        existing_data = self._load_existing_listings()
        top_ids = set(self._load_top_listings().get("listings", {}).keys())

        saved_count = 0
        skipped_top = 0
        
        for listing_id, listing_data in new_listings_data.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø–æ–ø–∞–≤—à–∏–µ –≤ —Ç–æ–ø
            if listing_id in top_ids:
                skipped_top += 1
                continue
            if listing_id not in existing_data["listings"]:
                existing_data["listings"][listing_id] = {}
            existing_data["listings"][listing_id][checked_date] = listing_data
            saved_count += 1
        
        self._save_listings(existing_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏—Å—Ç–∏–Ω–≥–∏ —Å—Ç–∞—Ä—à–µ 1 –¥–Ω—è –∏ –Ω–∞—Ö–æ–¥–∏–º —Ç–æ–ø—ã
        potential_tops = self._check_listings_age(existing_data, checked_date)
        
        # –£–¥–∞–ª—è–µ–º –Ω–æ–≤—ã–µ —Ç–æ–ø—ã –∏–∑ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö
        if potential_tops:
            for lid in potential_tops:
                existing_data["listings"].pop(lid, None)
            self._save_listings(existing_data)
        
        logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ {saved_count} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —Å –¥–∞—Ç–æ–π {checked_date} (–ø—Ä–æ–ø—É—â–µ–Ω–æ –∫–∞–∫ —Ç–æ–ø: {skipped_top})")
        print(f"üíé –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ –≤ tops/ (–ø—Ä–æ–ø—É—â–µ–Ω–æ –∫–∞–∫ —Ç–æ–ø: {skipped_top})")
        
        if potential_tops:
            print(f"üî• –ù–∞–π–¥–µ–Ω–æ {len(potential_tops)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–ø-—Ö–∏—Ç–æ–≤!")


    
    def process_new_products(self, new_products: Dict[str, str], checked_date: str = None):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç"""
        if not new_products:
            print("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        if not checked_date:
            checked_date = datetime.now().strftime("%d.%m.%Y_%H.%M")
        
        print(f"\n=== –ê–ù–ê–õ–ò–ó –ù–û–í–´–• –¢–û–í–ê–†–û–í –ß–ï–†–ï–ó EVERBEE ===")
        print(f"üìÖ –î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {checked_date}")
        print(f"üì¶ –¢–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(new_products)}")

        # –û—á–∏—Å—Ç–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –æ—Ç —É–∂–µ-—Ç–æ–ø–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
        self.cleanup_perspective_from_tops()
        
        listings_data = self.analyze_new_listings(new_products, checked_date)
        
        if listings_data:
            self.update_listings_data(listings_data, checked_date)
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
            logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
