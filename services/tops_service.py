"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–æ–ø —Ç–æ–≤–∞—Ä–∞–º–∏
"""
import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Callable
from utils.everbee_client import EverBeeClient


class TopsService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ø —Ç–æ–≤–∞—Ä–æ–≤"""
    
    def __init__(self, tops_dir: str = "output/tops"):
        self.tops_dir = tops_dir
        self.everbee_client = EverBeeClient()
        self.listings_file = os.path.join(self.tops_dir, "new_perspective_listings.json")
        self.top_listings_file = os.path.join(self.tops_dir, "top-listings.json")
        self.archived_listings_file = os.path.join(self.tops_dir, "archived_listings.json")
        # –ü–æ—Ä–æ–≥ –∑—Ä–µ–ª–æ—Å—Ç–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ–ø–∞
        self.maturity_days = 60  # ~2 –º–µ—Å—è—Ü–∞
        self.views_threshold = 25.0  # ~25 –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤/–¥–µ–Ω—å
        self.likes_threshold = 1.0   # ~1 –ª–∞–π–∫/–¥–µ–Ω—å
        self.tolerance = 0.8         # –î–æ–ø—É—Å–∫ 20%
        # –ö–æ–ª–±—ç–∫-—É–≤–µ–¥–æ–º–∏—Ç–µ–ª—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.notifier: Optional[Callable[[Dict], None]] = None
        os.makedirs(self.tops_dir, exist_ok=True)
    
    def _load_existing_listings(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤"""
        if os.path.exists(self.listings_file):
            try:
                with open(self.listings_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        return {"listings": {}}
    
    def _save_listings(self, data: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤"""
        try:
            with open(self.listings_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logging.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.listings_file}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")

    # ===== –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —Ç–æ–ø–æ–≤/–∞—Ä—Ö–∏–≤–∞ =====
    def _load_top_listings(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏"""
        if os.path.exists(self.top_listings_file):
            try:
                with open(self.top_listings_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–æ–≤: {e}")
        return {"listings": {}}

    def _save_top_listings(self, data: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏"""
        try:
            with open(self.top_listings_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logging.info(f"–¢–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {self.top_listings_file}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–æ–≤: {e}")

    def _load_archived_listings(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—Ä—Ö–∏–≤ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤"""
        if os.path.exists(self.archived_listings_file):
            try:
                with open(self.archived_listings_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ö–∏–≤–∞: {e}")
        return {"listings": {}}

    def _save_archived_listings(self, data: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—Ä—Ö–∏–≤ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤"""
        try:
            with open(self.archived_listings_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logging.info(f"–ê—Ä—Ö–∏–≤ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {self.archived_listings_file}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–∞: {e}")

    def set_notifier(self, notifier: Callable[[Dict], None]):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–ª–±—ç–∫ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –æ —Ç–æ–ø–∞—Ö"""
        self.notifier = notifier

    def cleanup_perspective_from_tops(self) -> int:
        """–£–¥–∞–ª—è–µ—Ç –∏–∑ new_perspective_listings.json –ª–∏—Å—Ç–∏–Ω–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ —Ç–æ–ø–∞—Ö.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö.
        """
        data = self._load_existing_listings()
        tops = self._load_top_listings()
        perspective = data.get("listings", {})
        top_ids = set(tops.get("listings", {}).keys())
        if not perspective or not top_ids:
            return 0
        removed = 0
        for lid in list(perspective.keys()):
            if lid in top_ids:
                perspective.pop(lid, None)
                removed += 1
        if removed:
            data["listings"] = perspective
            self._save_listings(data)
            logging.info(f"–û—á–∏—Å—Ç–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö: —É–¥–∞–ª–µ–Ω–æ {removed} —É–∂–µ-—Ç–æ–ø –ª–∏—Å—Ç–∏–Ω–≥–æ–≤")
            print(f"üßπ –û—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª–µ–Ω–æ {removed} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤, —É–∂–µ –ø–æ–ø–∞–≤—à–∏—Ö –≤ —Ç–æ–ø")
        return removed
    
    def analyze_new_listings(self, new_products: Dict[str, str], checked_date: str) -> Dict[str, Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ EverBee API"""
        if not new_products:
            print("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return {}
        
        print(f"üìä –ê–Ω–∞–ª–∏–∑ {len(new_products)} –Ω–æ–≤—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ EverBee...")
        logging.info(f"–ê–Ω–∞–ª–∏–∑ {len(new_products)} –Ω–æ–≤—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ EverBee...")
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–ø-–ª–∏—Å—Ç–∏–Ω–≥–∏ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        top_existing = set(self._load_top_listings().get("listings", {}).keys())
        listing_ids = [lid for lid in new_products.keys() if lid not in top_existing]
        
        response = self.everbee_client.get_listings_batch(listing_ids)
        
        if not response or "results" not in response:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
            logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
            return {}
        
        results = {}
        for listing in response.get("results", []):
            listing_id = str(listing.get("listing_id"))
            if listing_id:
                extracted_data = self.everbee_client.extract_listing_data(listing)
                results[listing_id] = extracted_data
        
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(results)} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ –æ—Ç EverBee")
        logging.info(f"–ü–æ–ª—É—á–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(results)} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤")
        return results
    
    def update_listings_data(self, new_listings_data: Dict[str, Dict], checked_date: str):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —Å –Ω–æ–≤–æ–π –¥–∞—Ç–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        existing_data = self._load_existing_listings()
        top_ids = set(self._load_top_listings().get("listings", {}).keys())

        saved_count = 0
        skipped_top = 0
        
        for listing_id, listing_data in new_listings_data.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø–æ–ø–∞–≤—à–∏–µ –≤ —Ç–æ–ø
            if listing_id in top_ids:
                skipped_top += 1
                continue
            if listing_id not in existing_data["listings"]:
                existing_data["listings"][listing_id] = {}
            existing_data["listings"][listing_id][checked_date] = listing_data
            saved_count += 1
        
        self._save_listings(existing_data)
        
        logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ {saved_count} –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ —Å –¥–∞—Ç–æ–π {checked_date} (–ø—Ä–æ–ø—É—â–µ–Ω–æ –∫–∞–∫ —Ç–æ–ø: {skipped_top})")
        print(f"üíé –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ –≤ tops/ (–ø—Ä–æ–ø—É—â–µ–Ω–æ –∫–∞–∫ —Ç–æ–ø: {skipped_top})")

    def evaluate_matured_listings(self) -> Dict[str, Dict]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ª–∏—Å—Ç–∏–Ω–≥–∏, –¥–æ—Å—Ç–∏–≥—à–∏–µ –∑—Ä–µ–ª–æ—Å—Ç–∏ (~2 –º–µ—Å—è—Ü–∞), –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∏—Ö –∫–∞–∫ –¢–û–ü –∏–ª–∏ –≤ –ê—Ä—Ö–∏–≤.
        –£—Å–ª–æ–≤–∏—è –¢–û–ü: ~25 –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤/–¥–µ–Ω—å –∏ ~1 –ª–∞–π–∫/–¥–µ–Ω—å (—Å –¥–æ–ø—É—Å–∫–æ–º).
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Ç–æ–ø–∞–º–∏ –∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ ID.
        """
        data = self._load_existing_listings()
        all_listings = data.get("listings", {})
        if not all_listings:
            return {"top": {}, "archived": []}

        top_json = self._load_top_listings()
        archived_json = self._load_archived_listings()

        top_added: Dict[str, Dict] = {}
        archived_ids: List[str] = []
        now = datetime.now()
        to_remove: List[str] = []

        for listing_id, snapshots in all_listings.items():
            if not snapshots:
                continue
            timestamps = sorted(snapshots.keys())
            first_ts = timestamps[0]
            last_ts = timestamps[-1]
            try:
                first_dt = datetime.strptime(first_ts, "%d.%m.%Y_%H.%M")
                last_dt = datetime.strptime(last_ts, "%d.%m.%Y_%H.%M")
            except Exception:
                # –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–µ—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑—Ä–µ–ª–æ—Å—Ç—å (2 –º–µ—Å ~ 60 –¥–Ω–µ–π)
            if (now - first_dt).days < self.maturity_days:
                continue

            days_observed = max((last_dt - first_dt).days, 1)
            first_data = snapshots.get(first_ts, {})
            last_data = snapshots.get(last_ts, {})

            v_start = (first_data.get("views") or 0)
            v_end = (last_data.get("views") or 0)
            f_start = (first_data.get("num_favorers") or 0)
            f_end = (last_data.get("num_favorers") or 0)

            views_per_day = (v_end - v_start) / days_observed if days_observed else 0.0
            likes_per_day = (f_end - f_start) / days_observed if days_observed else 0.0

            is_top = (
                views_per_day >= self.views_threshold * self.tolerance and
                likes_per_day >= self.likes_threshold * self.tolerance
            )

            summary = {
                "listing_id": listing_id,
                "discovered_at": first_ts,
                "last_checked": last_ts,
                "url": last_data.get("url", ""),
                "days_observed": days_observed,
                "avg_views_per_day": round(views_per_day, 2),
                "avg_likes_per_day": round(likes_per_day, 2),
            }

            if is_top:
                top_json.setdefault("listings", {})
                top_json["listings"][listing_id] = summary
                top_added[listing_id] = summary
                print(
                    f"üîù –¢–æ–ø-—Ö–∏—Ç: {listing_id} "
                    f"({summary['avg_views_per_day']}/–¥–µ–Ω—å, {summary['avg_likes_per_day']}/–¥–µ–Ω—å) "
                    f"{summary['url']}"
                )
                if self.notifier:
                    try:
                        self.notifier(summary)
                    except Exception as e:
                        logging.error(f"–û—à–∏–±–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è —Ç–æ–ø –ª–∏—Å—Ç–∏–Ω–≥–∞ {listing_id}: {e}")
            else:
                archived_json.setdefault("listings", {})
                archived_json["listings"][listing_id] = {**summary, "reason": "below_threshold"}
                archived_ids.append(listing_id)
                print(
                    f"üóÑÔ∏è –ê—Ä—Ö–∏–≤: {listing_id} "
                    f"({summary['avg_views_per_day']}/–¥–µ–Ω—å, {summary['avg_likes_per_day']}/–¥–µ–Ω—å) "
                    f"{summary['url']}"
                )

            to_remove.append(listing_id)

        # –£–¥–∞–ª—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if to_remove:
            for lid in to_remove:
                data["listings"].pop(lid, None)
            self._save_listings(data)
            if top_added:
                self._save_top_listings(top_json)
            if archived_ids:
                self._save_archived_listings(archived_json)

        return {"top": top_added, "archived": archived_ids}
    
    def process_new_products(self, new_products: Dict[str, str], checked_date: str = None):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã: –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç"""
        if not new_products:
            print("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        if not checked_date:
            checked_date = datetime.now().strftime("%d.%m.%Y_%H.%M")
        
        print(f"\n=== –ê–ù–ê–õ–ò–ó –ù–û–í–´–• –¢–û–í–ê–†–û–í –ß–ï–†–ï–ó EVERBEE ===")
        print(f"üìÖ –î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {checked_date}")
        print(f"üì¶ –¢–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(new_products)}")

        # –û—á–∏—Å—Ç–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö –æ—Ç —É–∂–µ-—Ç–æ–ø–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
        self.cleanup_perspective_from_tops()
        
        listings_data = self.analyze_new_listings(new_products, checked_date)
        
        if listings_data:
            self.update_listings_data(listings_data, checked_date)
            eval_result = self.evaluate_matured_listings()
            top_count = len(eval_result.get("top", {})) if eval_result else 0
            archived_count = len(eval_result.get("archived", [])) if eval_result else 0
            if top_count or archived_count:
                print(f"üèÅ –ò—Ç–æ–≥: –≤ —Ç–æ–ø –¥–æ–±–∞–≤–ª–µ–Ω–æ {top_count}, –≤ –∞—Ä—Ö–∏–≤ {archived_count}")
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
            logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç EverBee")
